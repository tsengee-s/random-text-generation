{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a8372aa",
   "metadata": {},
   "source": [
    "## Author:Tsengee Sundui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1326882",
   "metadata": {},
   "source": [
    "First, let's download the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a59bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_location = 'C:/Users/sundu/OneDrive - The University of Chicago/Documents/Winter 2023/walden.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56580a83",
   "metadata": {},
   "source": [
    "## 1. Write Python code to count the number of lines in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b2b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 9847\n"
     ]
    }
   ],
   "source": [
    "f = open(data_file_location, 'r', encoding='utf8')\n",
    "lines = f.readlines()\n",
    "lines = [line.strip() for line in lines]\n",
    "count = 0\n",
    "for line in lines:\n",
    "    #only counting the non-empty lines that actually contain text\n",
    "    if len(line) != 0:\n",
    "        count += 1\n",
    "print(\"Number of lines:\", count)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1257de0c",
   "metadata": {},
   "source": [
    "## 2. Print the first 15 lines (hint: if using loops, look up the ‘break’ keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ded58a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg eBook of Walden, by Henry David Thoreau\n",
      "This eBook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. You may copy it, give it away or re-use it under the terms\n",
      "of the Project Gutenberg License included with this eBook or online at\n",
      "www.gutenberg.org. If you are not located in the United States, you\n",
      "will have to check the laws of the country where you are located before\n",
      "using this eBook.\n",
      "Title: Walden\n",
      "Author: Henry David Thoreau\n",
      "Release Date: January, 1995 [eBook #205]\n",
      "[Most recently updated: January 28, 2021]\n",
      "Language: English\n",
      "Character set encoding: UTF-8\n",
      "Produced by: Judith Boss, and David Widger\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_location, 'r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    counter = 0\n",
    "    for line in lines:\n",
    "        if len(line) != 0:\n",
    "            print(line)\n",
    "            counter += 1\n",
    "        if counter == 15: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6de363",
   "metadata": {},
   "source": [
    "## 3. Print the first 30 lines, after you have: \n",
    "A. Removed commas, periods, colons and semicolons and \n",
    "B. Converted all characters to lower case and \n",
    "C. Removed any extra spaces (hint strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f942babd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿the project gutenberg ebook of walden by henry david thoreau\n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever you may copy it give it away or re-use it under the terms\n",
      "of the project gutenberg license included with this ebook or online at\n",
      "wwwgutenbergorg if you are not located in the united states you\n",
      "will have to check the laws of the country where you are located before\n",
      "using this ebook\n",
      "title walden\n",
      "author henry david thoreau\n",
      "release date january 1995 [ebook #205]\n",
      "[most recently updated january 28 2021]\n",
      "language english\n",
      "character set encoding utf-8\n",
      "produced by judith boss and david widger\n",
      "*** start of the project gutenberg ebook walden ***\n",
      "walden\n",
      "and\n",
      "on the duty of civil disobedience\n",
      "by henry david thoreau\n",
      "cover\n",
      "contents\n",
      "walden\n",
      "economy\n",
      "where i lived and what i lived for\n",
      "reading\n",
      "sounds\n",
      "solitude\n",
      "visitors\n",
      "the bean-field\n",
      "the village\n",
      "the ponds\n",
      "baker farm\n",
      "higher laws\n",
      "brute neighbors\n",
      "house-warming\n",
      "former inhabitants and winter visitors\n",
      "winter animals\n",
      "the pond in winter\n",
      "spring\n",
      "conclusion\n",
      "on the duty of civil disobedience\n",
      "walden\n",
      "economy\n",
      "when i wrote the following pages or rather the bulk of them i lived\n",
      "alone in the woods a mile from any neighbor in a house which i had\n",
      "built myself on the shore of walden pond in concord massachusetts\n",
      "and earned my living by the labor of my hands only i lived there two\n",
      "years and two months at present i am a sojourner in civilized life\n",
      "again\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_location, 'r', encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.replace(',', '') for line in lines]\n",
    "    lines = [line.replace('.', '') for line in lines]\n",
    "    lines = [line.replace(':', '') for line in lines]\n",
    "    lines = [line.replace(';', '') for line in lines]\n",
    "    lines = [line.lower() for line in lines]\n",
    "    lines = [line.strip() for line in lines]\n",
    "    counter = 0\n",
    "    for line in lines:\n",
    "        if len(line) != 0:\n",
    "            print(line)\n",
    "            counter += 1\n",
    "        if counter == 30: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5541be2",
   "metadata": {},
   "source": [
    "## 4. Count the number of unique words in the file (after transforming the text using logic from #3). How often are the following words used: \"dawn\", \"distasteful\", \"employment?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b991fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 11359\n",
      "Dawn: 10\n",
      "Distasteful: 0\n",
      "Employment: 7\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "with open(data_file_location, 'r', encoding='utf-8-sig') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.lower() for line in lines]\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line.translate (str.maketrans('','', string.punctuation)) for line in lines]\n",
    "    words = [line.split() for line in lines]\n",
    "    \n",
    "    unique = []\n",
    "    \n",
    "    c1 = 0\n",
    "    c2 = 0\n",
    "    c3 = 0\n",
    "    \n",
    "    for i in words:\n",
    "        for j in i:\n",
    "            if j not in unique and j.isalpha():\n",
    "                unique.append(j)\n",
    "            if j == 'dawn':\n",
    "                c1+=1\n",
    "            elif j == 'distasteful':\n",
    "                c2 +=1\n",
    "            elif j == 'employment':\n",
    "                c3 +=1\n",
    "    print(\"Number of unique words:\", len(unique))\n",
    "    print(\"Dawn: \", c1, \"\\n\", \"Distasteful: \", c2, \"\\n\", \"Employment: \", c3, sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c6ec0",
   "metadata": {},
   "source": [
    "## 5. Create a list of alphabetically sorted unique words and display the first 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c15b85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'abandon', 'abandoned', 'abandonment', 'abandons']\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_location, 'r', encoding='utf-8-sig') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.lower() for line in lines]\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line.translate (str.maketrans('','', string.punctuation)) for line in lines]\n",
    "    words = [line.split() for line in lines]\n",
    "    \n",
    "    unique = []\n",
    "    \n",
    "    for i in words: \n",
    "        for j in i:\n",
    "            if j not in unique and j.isalpha():\n",
    "                unique.append(j)\n",
    "    \n",
    "    unique.sort()\n",
    "    print(unique[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db3966",
   "metadata": {},
   "source": [
    "## 6. ... display the last 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14306ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æolian', 'æs', 'æschylus', 'æsculapius', 'éclat']\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_location, 'r', encoding='utf-8-sig') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.lower() for line in lines]\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line.translate (str.maketrans('','', string.punctuation)) for line in lines]\n",
    "    words = [line.split() for line in lines]\n",
    "    \n",
    "    unique = []\n",
    "    \n",
    "    for i in words: \n",
    "        for j in i:\n",
    "            if j not in unique and j.isalpha():\n",
    "                unique.append(j)\n",
    "    \n",
    "    unique.sort()\n",
    "    print(unique[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999e86f",
   "metadata": {},
   "source": [
    "## 7. ... display 3rd, 4th and 5th words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05517fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandoned', 'abandonment', 'abandons']\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_location, 'r', encoding='utf-8-sig') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.lower() for line in lines]\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line.translate (str.maketrans('','', string.punctuation)) for line in lines]\n",
    "    words = [line.split() for line in lines]\n",
    "    \n",
    "    unique = []\n",
    "    \n",
    "    for i in words: \n",
    "        for j in i:\n",
    "            if j not in unique and j.isalpha():\n",
    "                unique.append(j)\n",
    "    \n",
    "    unique.sort()\n",
    "    print(unique[2:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515eb6df",
   "metadata": {},
   "source": [
    "## 8. ... display 5 words  which contain the letter 'L' (ignore case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "148e7c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walden\n",
      "world\n",
      "almost\n",
      "license\n",
      "included\n"
     ]
    }
   ],
   "source": [
    "with open(data_file_location, 'r', encoding='utf-8-sig') as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.lower() for line in lines]\n",
    "    lines = [line.strip() for line in lines]\n",
    "    lines = [line.translate (str.maketrans('','', string.punctuation)) for line in lines]\n",
    "    words = [line.split() for line in lines]\n",
    "    \n",
    "    unique = []\n",
    "    \n",
    "    for i in words: \n",
    "        for j in i:\n",
    "            if j not in unique and j.isalpha():\n",
    "                unique.append(j)\n",
    "    \n",
    "    count = 0\n",
    "    for w in unique:\n",
    "        if 'l' in w:\n",
    "            count +=1\n",
    "            print(w)\n",
    "        if count == 5: break   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7d44f",
   "metadata": {},
   "source": [
    "## 9. Create a file containing a \"cleaned\" version of the text with the following transformations: \n",
    "    A. remove extra spaces and reformat the text so there is one English sentence per line. (this is done most easily if you load the whole file, rather than processing it line by line)\n",
    "    B. remove all punctuation \n",
    "    C. convert all characters to lower case \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "025a539a-d96b-4d26-b234-5573bdfc240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "with open(data_file_location, 'r', encoding='utf-8-sig') as file:\n",
    "    #skipping past the first 79 lines (title, table of contents, etc.)\n",
    "    #and getting straight to the text\n",
    "    for i in range(79):\n",
    "        next(file)\n",
    "    text = file.read()\n",
    "    #Remove extra spaces\n",
    "    text = re.sub(\"\\s+\", \" \", text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    #Splitting so that there is one English sentence per line\n",
    "    sentences = re.split(\"(?<=[.!?]) +\", text)\n",
    "     \n",
    "with open(\"cleaned_walden.txt\", \"w\") as f1:\n",
    "    for sentence in sentences:\n",
    "        #Remove punctuation\n",
    "        sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        #Convert to lowercase\n",
    "        sentence = sentence.lower()\n",
    "        f1.write(sentence.strip()+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4638aecb-80d1-4dc6-89df-2e4f5e3f800a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
